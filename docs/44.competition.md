# Textual inversion usage competition

We are hosting a competition where the community can showcase their most inventive use of textual inversion concepts in text-to-image or text-to-video.

Our compute cluster; `Nataili`, currently comprises of 3 nodes, two have 3090, the other has 2 x A5000.

We estimate `Nataili` can handle 12 concepts per hour, and we can add more workers if there is high demand.

Hopefully demand will be high, we want to train **hundreds** of new concepts!

# Schedule

2022/10/20 - Competition announced, training begins

2022/10/22 12AM UTC - Stage 2 begins, text to image command opened for usage

2022/10/22 12PM UTC - Stage 1 ends

2022/10/24 12PM UTC - Stage 2 ends

2022/10/24 6-12PM UTC - Winners announced


# What does `most inventive use` mean?

Whatever you want it to mean! be creative! experiment! 

There are several categories we will look at:

* anything that's particularly creative, ~ artistic ~ or a e s t h e t i c

![20221019203426_00000](https://user-images.githubusercontent.com/106811348/197045193-d6f9c56b-9989-4f1c-b42a-bb02d62d77cd.png)

* composition; meaning anything related to how big things are, their position, the angle, etc

* styling; 

![image](https://user-images.githubusercontent.com/106811348/197045629-029ba6f5-1f79-475c-9ce7-969aaf3d253b.png)

* `The Sims(TM): Stable Diffusion edition`

## So I can trai-

* Yes, as long as it's sfw

## `The Sims(TM): Stable Diffusion edition` ?

For this event the theme is “The Sims: Stable Diffusion edition”. 

So we have selected a subset of 1000 products from Amazon Berkely Objects dataset.
You can browse them here (link will be here).

Each product has images from multiple angles, the train concept command accepts up to 10 images, so choose the angles and modify backgrounds, experiment!

The goal with this category is to generate an image using the trained object, and the other categories apply, your imagination is the only limit! style a couch, try to make a BIG couch, try to make a couch on top of a mountain, try to make a vaporwave couch, anything!

# How do I train a concept using the discord bot?

Type `/trainconcept` then press tab to go through the fields

`Concept name` is just a name for your concept, it doesn't have to be a single word

`Placeholder` is what you will use in prompts to represent your concept
Add `<` and `>` so it is unique, multiple words should be hyphenated

`Initializer` is used as the starting point for training your concept, so this should be a single word that represents your concept

Minimum 2 images. Squareish aspect ratios work best

![Untitled-2](https://user-images.githubusercontent.com/106811348/197035834-cc973e29-31f8-48de-be2d-788fbe938b2e.png)
![image](https://user-images.githubusercontent.com/106811348/197035870-b91ef2a8-0ffd-47e1-a8df-9600df26cd6b.png)

# How do I use the trained concept?

## Prompting with concepts

When your concept is trained you can use it in prompts.

`a cute <nvidiafu> as an astronaut`:

![image](https://user-images.githubusercontent.com/106811348/197037250-044ea241-72a5-4caa-b772-35034245b4b6.png)

or `a green <green-couch> sitting on top of a floor, a 3D render, trending on polycount, minimalism, rendered in cinema4d`:

![image](https://user-images.githubusercontent.com/106811348/197037344-7ce72188-9129-4ba2-8a28-cba5fd664a9c.png)

## Using concepts in the webui

The discord bot will give you a link to a `.zip` file, download this, extract it, and put the folder in `stable-diffusion-webui/models/custom/sd-concepts-library`

![image](https://user-images.githubusercontent.com/106811348/197037892-ce53bea4-d1db-4b25-bb7c-7dfe4d71b2b1.png)
